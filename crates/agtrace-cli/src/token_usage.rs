/// Type-safe token usage tracking to prevent context window calculation bugs.
///
/// Design rationale:
/// - Raw i32 values are error-prone (easy to forget including cache_read)
/// - Newtype pattern ensures each token type is used correctly
/// - ContextWindowUsage aggregates all tokens with compile-time guarantees
/// - Impossible to accidentally exclude cache_read from context window
use std::ops::Add;

/// Fresh input tokens (new content, not from cache)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct FreshInputTokens(pub i32);

/// Tokens used to create new cache entries
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct CacheCreationTokens(pub i32);

/// Tokens read from existing cache entries
///
/// IMPORTANT: These tokens DO consume context window even though billing is cheaper.
/// The LLM still processes these tokens, so they count toward the limit.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct CacheReadTokens(pub i32);

/// Output tokens generated by the model
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct OutputTokens(pub i32);

impl Add for FreshInputTokens {
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Self(self.0 + rhs.0)
    }
}

impl Add for CacheCreationTokens {
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Self(self.0 + rhs.0)
    }
}

impl Add for CacheReadTokens {
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Self(self.0 + rhs.0)
    }
}

impl Add for OutputTokens {
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Self(self.0 + rhs.0)
    }
}

/// Complete snapshot of token usage for a single turn.
///
/// This type makes it IMPOSSIBLE to forget including cache_read tokens
/// in context window calculations - the compiler enforces correct usage.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct ContextWindowUsage {
    pub fresh_input: FreshInputTokens,
    pub cache_creation: CacheCreationTokens,
    pub cache_read: CacheReadTokens, // Explicitly included - cannot be forgotten
    pub output: OutputTokens,
}

impl ContextWindowUsage {
    /// Create a new context window usage snapshot
    pub fn new(
        fresh_input: FreshInputTokens,
        cache_creation: CacheCreationTokens,
        cache_read: CacheReadTokens,
        output: OutputTokens,
    ) -> Self {
        Self {
            fresh_input,
            cache_creation,
            cache_read,
            output,
        }
    }

    /// Create from raw i32 values (for compatibility)
    pub fn from_raw(fresh_input: i32, cache_creation: i32, cache_read: i32, output: i32) -> Self {
        Self {
            fresh_input: FreshInputTokens(fresh_input),
            cache_creation: CacheCreationTokens(cache_creation),
            cache_read: CacheReadTokens(cache_read),
            output: OutputTokens(output),
        }
    }

    /// Input-side tokens (what LLM receives this turn)
    ///
    /// Includes: fresh input + cache creation + cache read
    /// All three types consume the context window.
    pub fn input_tokens(&self) -> i32 {
        self.fresh_input.0 + self.cache_creation.0 + self.cache_read.0
    }

    /// Output-side tokens (what LLM generates this turn)
    pub fn output_tokens(&self) -> i32 {
        self.output.0
    }

    /// Context window tokens consumed this turn
    ///
    /// This is the value that counts toward the model's context limit.
    /// cache_read is ALWAYS included - the type system guarantees this.
    pub fn context_window_tokens(&self) -> i32 {
        self.input_tokens() + self.output_tokens()
    }

    /// Check if usage is zero (no tokens)
    pub fn is_empty(&self) -> bool {
        self.context_window_tokens() == 0
    }
}

impl Add for ContextWindowUsage {
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Self {
            fresh_input: self.fresh_input + rhs.fresh_input,
            cache_creation: self.cache_creation + rhs.cache_creation,
            cache_read: self.cache_read + rhs.cache_read,
            output: self.output + rhs.output,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_context_window_usage_calculation() {
        let usage = ContextWindowUsage::from_raw(100, 200, 300, 50);

        assert_eq!(usage.input_tokens(), 600); // 100 + 200 + 300
        assert_eq!(usage.output_tokens(), 50);
        assert_eq!(usage.context_window_tokens(), 650); // 600 + 50
    }

    #[test]
    fn test_cache_read_always_included() {
        // This test documents that cache_read MUST be included
        // The type system makes it impossible to exclude
        let usage = ContextWindowUsage::from_raw(10, 20, 5000, 30);

        // cache_read (5000) is always part of the context window
        assert_eq!(usage.context_window_tokens(), 5060); // Not 60!
    }

    #[test]
    fn test_add_usage() {
        let usage1 = ContextWindowUsage::from_raw(100, 200, 300, 50);
        let usage2 = ContextWindowUsage::from_raw(10, 20, 30, 5);

        let total = usage1 + usage2;

        assert_eq!(total.fresh_input.0, 110);
        assert_eq!(total.cache_creation.0, 220);
        assert_eq!(total.cache_read.0, 330);
        assert_eq!(total.output.0, 55);
        assert_eq!(total.context_window_tokens(), 715);
    }

    #[test]
    fn test_default_is_empty() {
        let usage = ContextWindowUsage::default();
        assert!(usage.is_empty());
        assert_eq!(usage.context_window_tokens(), 0);
    }
}
